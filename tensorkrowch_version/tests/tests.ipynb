{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20e6e728",
   "metadata": {},
   "source": [
    "# MPS Hamiltonian Learning with TensorKrowch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "d30c3c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "import tensorkrowch as tk\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import yaml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365ea603",
   "metadata": {},
   "source": [
    "### Things to do:\n",
    "\n",
    "This will be a pytorch version of the Hamiltonian learning problem, where the NN has a layer with an MPS structure from tensorkrowch. There are a few things that I need to sort out:\n",
    "1. This NN doesn't train from data, it starts from an ansatz and modifies it until it finds the optimal solution\n",
    "2. I still need to run the dynamics for every epoch, which consist on:\n",
    "    2.1. Taking initial state and applyting rotations in the X,Y and Z directions, with the option to customize which rotations I want to apply\n",
    "    2.2. Doing a time evolution of the resulting state under a Hamiltonian. The Hamiltonian contains only interaction terms, and it also must be customizable\n",
    "3. After running the Hamiltonian, we extract bitstring probabilities and compute nll loss function with the input data, which are the generated bitstrings "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a596daf3",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "551129c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_path):\n",
    "    '''Load configuration from YAML file'''\n",
    "    with open(config_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "\n",
    "def load_experimental_data(config):\n",
    "    \"\"\"Load experimental/simulated data\"\"\"\n",
    "    N = config[\"L\"]\n",
    "    chi = config['bond_dimension']\n",
    "    T_max = config[\"t_max\"]\n",
    "    search_pattern = f\"../data/experimental_data_quantum_sampling_L{N}_Chi_{chi}_*_counts.csv\"\n",
    "    files = glob.glob(search_pattern)\n",
    "\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No data found for L={N}\")\n",
    "\n",
    "    config_file = files[0]\n",
    "    file_core = config_file.replace(\".csv\", \"\").replace(\"../data/experimental_data_quantum_sampling_\", \"\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"LOADING DATA: {file_core}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    df_counts = pd.read_csv(f\"../data/experimental_data_quantum_sampling_{file_core}.csv\")\n",
    "        \n",
    "    # Remove leading single quote if present\n",
    "    if df_counts['bitstring'].astype(str).str.startswith(\"'\").all():\n",
    "        df_counts['bitstring'] = df_counts['bitstring'].str[1:]\n",
    "    \n",
    "    # Now extract values\n",
    "    bitstrings = df_counts['bitstring'].values.astype(str)\n",
    "    counts_shots = df_counts['count'].values.astype(np.int32)\n",
    "    \n",
    "    return bitstrings, counts_shots\n",
    "\n",
    "\n",
    "def local_probability_tensor(strings, counts):\n",
    "    '''Calculates probabilities of each qubit, returning vector of size L\n",
    "    containing the probs of each qubit being 0 or 1'''\n",
    "    L = len(strings[0])\n",
    "    total_counts = sum(counts)\n",
    "    \n",
    "    prob_matrix = torch.zeros((1, L, 2)) #First index is batch. Needed for feeding into NN\n",
    "    \n",
    "    for bitstring, count in zip(strings, counts):\n",
    "        for qubit in range(L):\n",
    "            bit_value = int(bitstring[qubit])\n",
    "            prob_matrix[0, qubit, bit_value] += count\n",
    "    \n",
    "    # Normalize by total counts\n",
    "    prob_matrix /= total_counts\n",
    "    \n",
    "    return prob_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f031b6",
   "metadata": {},
   "source": [
    "## Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "7c36a6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paulis(dtype=torch.complex64):\n",
    "    '''Creates single-qubit basis operators'''\n",
    "    sx = torch.tensor([[0., 1.], [1., 0.]], dtype=dtype)\n",
    "    sy = torch.tensor([[0., -1j], [1j, 0.]], dtype=dtype)\n",
    "    sz = torch.tensor([[1., 0.], [0., -1.]], dtype=dtype)\n",
    "    id2 = torch.eye(2, dtype=dtype)\n",
    "    return sx, sy, sz, id2\n",
    "\n",
    "def kron_n(ops):\n",
    "    '''Tensor product of a list of operators'''\n",
    "    out = ops[0]\n",
    "    for A in ops[1:]:\n",
    "        out = torch.kron(out, A)\n",
    "    return out\n",
    "\n",
    "\n",
    "def x_rotation(theta, dtype=torch.complex64):\n",
    "    sx = torch.tensor([[0., 1.], [1., 0.]], dtype=dtype)\n",
    "    return torch.matrix_exp(-1j * theta / 2 * sx)\n",
    "\n",
    "def y_rotation(theta, dtype=torch.complex64):\n",
    "    sy = torch.tensor([[0., -1j], [1j, 0.]], dtype=dtype)\n",
    "    return torch.matrix_exp(-1j * theta / 2 * sy)\n",
    "\n",
    "def z_rotation(theta, dtype=torch.complex64):\n",
    "    sz = torch.tensor([[1., 0.], [0., -1.]], dtype=dtype)\n",
    "    return torch.matrix_exp(-1j * theta / 2 * sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "78840517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_initial_state(L, kind, dtype=torch.complex64):\n",
    "    \"\"\"Prepare initial quantum states for L qubits.\"\"\"\n",
    "    if kind == 'all_zeros':\n",
    "        psi0 = torch.zeros(2**L, dtype=dtype)\n",
    "        psi0[0] = 1.0\n",
    "        \n",
    "    elif kind == 'all_plus':\n",
    "        plus = torch.ones(2, dtype=dtype) / np.sqrt(2)\n",
    "        psi0 = plus\n",
    "        for _ in range(L - 1):\n",
    "            psi0 = torch.kron(psi0, plus)\n",
    "            \n",
    "    else:\n",
    "        raise ValueError(f\"Initial state '{kind}' not recognized. \"\n",
    "                        f\"Use 'all_zeros' or 'all_plus'\")\n",
    "    return psi0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "f949bde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OperatorClass:\n",
    "    '''Class that contains a list of all the operator types the Hamiltonian will have\n",
    "       The operators will be applied to each qubit, and we will allow for the construction of any\n",
    "       combination of Pauli strings \n",
    "    '''\n",
    "    def __init__(self, L, dtype=torch.complex64):\n",
    "\n",
    "        self.L = L\n",
    "        self.dim = 2**L\n",
    "        self.pauli_basis = {}\n",
    "        self.pauli_basis['X'], self.pauli_basis['Y'], self.pauli_basis['Z'], self.pauli_basis['I'] = paulis(dtype)\n",
    "        self.operators = []\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.operators)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.operators[idx]\n",
    "    \n",
    "    def add_operators(self, pauli_string:str):\n",
    "        #e.g. 'X','Y','ZZ'\n",
    "        '''Adds one type of operator at a time. It loops through all the qubits, \n",
    "        and for each position does the tensor product of the whole chain, with the \n",
    "        required qubits substituted by the operators of the string'''\n",
    "\n",
    "        if len(pauli_string) > self.L:\n",
    "            raise ValueError(f\"Pauli string '{pauli_string}' longer than system size {self.L}\")\n",
    "        \n",
    "        if not all(char in 'XYZI' for char in pauli_string):\n",
    "            raise ValueError(f\"Invalid character in '{pauli_string}'. Use only X, Y, Z, I\")\n",
    "        \n",
    "        for i in range(self.L - len(pauli_string) + 1):\n",
    "                #Create identity operators for each qubit\n",
    "                ops = [self.pauli_basis['I']]*self.L\n",
    "                for j, char in enumerate(pauli_string):\n",
    "                     #Build string\n",
    "                     ops[i+j] = self.pauli_basis[char]\n",
    "                self.operators.append(kron_n(ops))\n",
    "        print(f\"{pauli_string} terms added to the Hamiltonian\")\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a11a645",
   "metadata": {},
   "source": [
    "## Manual NN\n",
    "\n",
    "These were the functions defined by Marcin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "db2551a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_forward(params, x):\n",
    "    h = x\n",
    "    for layer in params[:-1]:\n",
    "        h = np.tanh(h @ layer[\"W\"] + layer[\"b\"])\n",
    "    last = params[-1]\n",
    "    return h @ last[\"W\"] + last[\"b\"]\n",
    "\n",
    "\n",
    "def init_mlp_params(layer_sizes, scale=0.1):\n",
    "    params = []\n",
    "    for i, (m, n) in enumerate(zip(layer_sizes[:-1], layer_sizes[1:])):\n",
    "        # Initialize weights with scaled normal distribution\n",
    "        W = scale * torch.randn((m, n))\n",
    "        # Initialize biases to zero\n",
    "        b = torch.zeros((n,))\n",
    "        params.append({\"W\": W, \"b\": b})\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3dfc28",
   "metadata": {},
   "source": [
    "## Pytorch NN\n",
    "\n",
    "Equivalent of Marcin's functions but with Pytorch syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "394c583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, layer_sizes):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        # Create linear layers\n",
    "        for i, (in_dim, out_dim) in enumerate(zip(layer_sizes[:-1], layer_sizes[1:])):\n",
    "            self.layers.append(nn.Linear(in_dim, out_dim))\n",
    "        \n",
    "        # Custom initialization (similar to your function)\n",
    "        self._initialize_parameters()\n",
    "    \n",
    "    def _initialize_parameters(self, scale=0.1):\n",
    "        \"\"\"Initialize weights with normal distribution and biases to zero.\"\"\"\n",
    "        for layer in self.layers:\n",
    "            nn.init.normal_(layer.weight, mean=0.0, std=scale)\n",
    "            nn.init.zeros_(layer.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Apply all but last layer with tanh activation\n",
    "        for i, layer in enumerate(self.layers[:-1]):\n",
    "            x = torch.tanh(layer(x))\n",
    "        \n",
    "        # Last layer - linear only (no activation)\n",
    "        x = self.layers[-1](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a32e902",
   "metadata": {},
   "source": [
    "## TensorKrowch NN\n",
    "\n",
    "My pytorch NN integrating MPS layer from TensorKrowch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "e09b1182",
   "metadata": {},
   "outputs": [],
   "source": [
    "#So, for input layer I should put number of possible bitstrings, and for output number of parameters to train. In the middle idk yet, but we'll see\n",
    "class MPS_MLP(nn.Module):\n",
    "    def __init__(self, L, chi, num_params, num_dims = []):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        layer_sizes = num_dims + [num_params]\n",
    "\n",
    "        # 1. MPS input layer: processes L×2 features → first hidden size (will be output size if no middle layers)\n",
    "        mps = tk.models.MPSLayer(\n",
    "            n_features=L,\n",
    "            in_dim=2,\n",
    "            out_dim=layer_sizes[0],  \n",
    "            bond_dim=chi\n",
    "        )\n",
    "        self.layers.append(mps)\n",
    "        \n",
    "        # 2. Middle layers (optional)\n",
    "        for i in range(len(layer_sizes)-1):\n",
    "            self.layers.append(nn.Linear(\n",
    "                layer_sizes[i],\n",
    "                layer_sizes[i+1]\n",
    "            ))\n",
    "        \n",
    "        if len(layer_sizes) > 1:\n",
    "        # 3. Final output layer: hidden → num_params\n",
    "            self.layers.append(nn.Linear(layer_sizes[-2], layer_sizes[-1]))\n",
    "        \n",
    "        # Custom initialization (similar to your function)\n",
    "        self._initialize_parameters()\n",
    "    \n",
    "    def _initialize_parameters(self, scale=0.1):\n",
    "        \"\"\"Initialize weights with normal distribution and biases to zero.\"\"\"\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, nn.Linear): #MPSLayer initializes itself\n",
    "                nn.init.normal_(layer.weight, mean=0.0, std=scale)\n",
    "                nn.init.zeros_(layer.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Apply all but last layer with tanh activation\n",
    "        for i, layer in enumerate(self.layers[:-1]):\n",
    "            x = torch.tanh(layer(x))\n",
    "        \n",
    "        # Last layer - linear only (no activation)\n",
    "        x = self.layers[-1](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "98223c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_rotations_direct(psi, params, L):\n",
    "#     \"\"\"\n",
    "#     Apply rotations by reshaping the state vector and applying 2x2 matrices.\n",
    "#     This is the most efficient method for single-qubit rotations.\n",
    "#     \"\"\"\n",
    "#     # Map parameter keys to rotation functions\n",
    "#     rot_funcs = {\n",
    "#         'rot_x': lambda theta: x_rotation(theta, dtype=psi.dtype),\n",
    "#         'rot_y': lambda theta: y_rotation(theta, dtype=psi.dtype),\n",
    "#         'rot_z': lambda theta: z_rotation(theta, dtype=psi.dtype)\n",
    "#     }\n",
    "    \n",
    "#     # Initialize per-qubit rotations as identity\n",
    "#     per_qubit_rots = [torch.eye(2, dtype=psi.dtype, device=psi.device) for _ in range(L)]\n",
    "    \n",
    "#     # Accumulate all rotations for each qubit\n",
    "#     for key, rot_func in rot_funcs.items():\n",
    "#         if key in params:\n",
    "#             rot_list = params[key]\n",
    "#             for i in range(L):\n",
    "#                 if i < len(rot_list):\n",
    "#                     per_qubit_rots[i] = rot_func(rot_list[i]) @ per_qubit_rots[i]\n",
    "    \n",
    "#     # Apply rotations qubit by qubit using tensor reshaping\n",
    "#     # This avoids constructing the full 2^L × 2^L matrix\n",
    "#     for i in range(L):\n",
    "#         # Reshape state to separate the i-th qubit\n",
    "#         shape = [2] * L\n",
    "#         psi_reshaped = psi.view(*shape)\n",
    "        \n",
    "#         # Move the i-th dimension to the front\n",
    "#         psi_reshaped = psi_reshaped.movedim(i, 0)\n",
    "        \n",
    "#         # Apply 2x2 rotation to each 2-element slice\n",
    "#         original_shape = psi_reshaped.shape\n",
    "#         psi_reshaped = psi_reshaped.view(2, -1)\n",
    "#         psi_reshaped = per_qubit_rots[i] @ psi_reshaped\n",
    "        \n",
    "#         # Restore shape and put dimension back\n",
    "#         psi_reshaped = psi_reshaped.view(original_shape)\n",
    "#         psi_reshaped = psi_reshaped.movedim(0, i)\n",
    "        \n",
    "#         psi = psi_reshaped.reshape(-1)\n",
    "    \n",
    "#     return psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43577c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rotations(psi, params, L):\n",
    "    sx, sy, sz, id2 = paulis()\n",
    "\n",
    "    rot_funcs = {\n",
    "    'rot_x': lambda theta: x_rotation(theta, dtype=psi.dtype),\n",
    "    'rot_y': lambda theta: y_rotation(theta, dtype=psi.dtype),\n",
    "    'rot_z': lambda theta: z_rotation(theta, dtype=psi.dtype)\n",
    "    }\n",
    "    \n",
    "    for key, rot_func in rot_funcs.items():\n",
    "        if key in params:\n",
    "            for i in range(L):\n",
    "                rot = kron_n([id2]*i + [rot_func(params[key][i])] + [id2]*(L-i-1))\n",
    "                #print(f'rot {key} in qubit {i} of angle {params[key][i]}')\n",
    "                psi = rot@psi\n",
    "                         \n",
    "    return psi  \n",
    " \n",
    "\n",
    "def rk4_step(state, H, t, dt, rhs_fun):\n",
    "    dt_c = torch.asarray(dt, dtype=state.dtype)\n",
    "    k1 = rhs_fun(H, t, state)\n",
    "    k2 = rhs_fun(H, t + 0.5*dt_c, state + 0.5*dt_c*k1)\n",
    "    k3 = rhs_fun(H, t + 0.5*dt_c, state + 0.5*dt_c*k2)\n",
    "    k4 = rhs_fun(H, t + dt_c, state + dt_c*k3)\n",
    "    state_next = state + (dt_c/6.0)*(k1 + 2*k2 + 2*k3 + k4)\n",
    "\n",
    "    \n",
    "    if state.ndim == 1:  # State vector\n",
    "        norm = torch.linalg.norm(state_next)\n",
    "        return state_next / (norm + 1e-12)\n",
    "    else:  # Density matrix\n",
    "        state_next = 0.5 * (state_next + state_next.conj().T)\n",
    "        trace = torch.trace(state_next).real\n",
    "        return state_next / (trace + 1e-12)\n",
    "\n",
    "\n",
    "def build_hamiltonian(L, theta, OPS_LIST):\n",
    "    '''Creates Hamiltonian from list of operators and corresponding weights'''\n",
    "\n",
    "    expected_shape = len(OPS_LIST)\n",
    "    \n",
    "    if len(theta) != expected_shape or len(OPS_LIST) != expected_shape:\n",
    "        raise ValueError(f\"Parameter/operator count mismatch\")\n",
    "    \n",
    "    H = torch.zeros((2**L, 2**L), dtype=torch.complex64)\n",
    "    for i in range(expected_shape):\n",
    "        H += theta[i] * OPS_LIST.operators[i]\n",
    "    \n",
    "    return H\n",
    "\n",
    "\n",
    "def schrodinger_rhs(H, t, psi):\n",
    "    return -1j * (H @ psi)\n",
    "\n",
    "\n",
    "def evolve_state(psi_t, H, t_grid):\n",
    "    rhs_fun = schrodinger_rhs\n",
    "    dt = t_grid[1] - t_grid[0]\n",
    "    for i,t in enumerate(t_grid[0:-1]):\n",
    "        dt = t_grid[i+1] - t_grid[i]\n",
    "        psi_t = rk4_step(psi_t, H, t, dt, rhs_fun)\n",
    " \n",
    "    return psi_t\n",
    "\n",
    "\n",
    "def time_evolution(psi, theta, OPS_LIST, L, t_grid):\n",
    "\n",
    "    H = build_hamiltonian(L, theta, OPS_LIST)\n",
    "\n",
    "    psi_t = evolve_state(psi, H, t_grid)\n",
    "\n",
    "    return psi_t\n",
    "\n",
    "\n",
    "def physics_computation(params, psi0, OPS_LIST, CONFIG, t_grid):\n",
    "\n",
    "    psi_rot = compute_rotations(psi0, params, CONFIG['L'])\n",
    "\n",
    "    psi_t = time_evolution(psi_rot, params['theta'], OPS_LIST, CONFIG['L'], t_grid)\n",
    "    \n",
    "    return psi_t\n",
    "\n",
    "def nll():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbd9b57",
   "metadata": {},
   "source": [
    "## Training algorithm\n",
    "\n",
    "Function that contains steps of one epoch\n",
    "\n",
    "1. Forward step of NN\n",
    "2. Simulation of physics (rotations + H evolution)\n",
    "3. Calculation of nll\n",
    "4. Backpropagation\n",
    "\n",
    "\n",
    "Function that loops for all epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "6e81351a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, params, n_epochs, single_qubit_probs, psi0, OPS_LIST, CONFIG, t_grid_fine, learning_rate, counts_shots):\n",
    "\n",
    "\n",
    "    loss_history = []\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    #initialization\n",
    "    optimizer.zero_grad()\n",
    "    psi_t = physics_computation(params, psi0, OPS_LIST, CONFIG, t_grid_fine)\n",
    "    loss = nll(psi_t, counts_shots)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    loss_history.append(loss.item())\n",
    "\n",
    "    for epoch_i in range(n_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass: NN predicts Hamiltonian parameters\n",
    "        predicted_params = model(single_qubit_probs)\n",
    "\n",
    "        #Dynamics of obtained parameters\n",
    "        psi_t = physics_computation(predicted_params[0], psi0, OPS_LIST, CONFIG, t_grid_fine)\n",
    "\n",
    "        #compute loss\n",
    "        loss = nll(psi_t, counts_shots)\n",
    "\n",
    "        #backpropagate and update optimizer\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "         \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "7741da7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/omichel/Desktop/qilimanjaro/projects/retech/retech_2025/tensorkrowch_version/config/MPS_learning_configuration.yaml\n",
      "\n",
      "============================================================\n",
      "LOADING DATA: L4_Chi_2_R50000_counts\n",
      "============================================================\n",
      "ZZ terms added to the Hamiltonian\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "nll() takes 0 positional arguments but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[249]\u001b[39m\u001b[32m, line 54\u001b[39m\n\u001b[32m     51\u001b[39m t_grid_fine = torch.arange(\u001b[32m0.0\u001b[39m, CONFIG[\u001b[33m\"\u001b[39m\u001b[33mt_max\u001b[39m\u001b[33m\"\u001b[39m] + CONFIG[\u001b[33m\"\u001b[39m\u001b[33mdt\u001b[39m\u001b[33m\"\u001b[39m]/\u001b[32m2\u001b[39m, CONFIG[\u001b[33m\"\u001b[39m\u001b[33mdt\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     52\u001b[39m learning_rate = CONFIG[\u001b[33m'\u001b[39m\u001b[33mlearning_rate\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msingle_qubit_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpsi0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOPS_LIST\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_grid_fine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcounts_shots\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[248]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, params, n_epochs, single_qubit_probs, psi0, OPS_LIST, CONFIG, t_grid_fine, learning_rate, counts_shots)\u001b[39m\n\u001b[32m      8\u001b[39m optimizer.zero_grad()\n\u001b[32m      9\u001b[39m psi_t = physics_computation(params, psi0, OPS_LIST, CONFIG, t_grid_fine)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m loss = \u001b[43mnll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpsi_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcounts_shots\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m loss.backward()\n\u001b[32m     12\u001b[39m optimizer.step()\n",
      "\u001b[31mTypeError\u001b[39m: nll() takes 0 positional arguments but 2 were given"
     ]
    }
   ],
   "source": [
    "config_file = \"/Users/omichel/Desktop/qilimanjaro/projects/retech/retech_2025/tensorkrowch_version/config/MPS_learning_configuration.yaml\"\n",
    "\n",
    "#load configuration\n",
    "print(config_file)\n",
    "CONFIG = load_config(config_file)\n",
    "\n",
    "# Load data\n",
    "bitstrings, counts_shots = load_experimental_data(CONFIG)\n",
    "\n",
    "#Main parameters\n",
    "L = CONFIG['L']\n",
    "CHI = CONFIG['bond_dimension']\n",
    "inital_state_kind = CONFIG['initial_state_kind']\n",
    "dim = 2**L\n",
    "\n",
    "#Reshape data into local probabilities\n",
    "single_qubit_probs = local_probability_tensor(bitstrings, counts_shots)\n",
    "\n",
    "psi0 = prepare_initial_state(L, inital_state_kind)\n",
    "\n",
    "#Initialize and onfigure Hamiltonian Ansatz\n",
    "OPS_LIST = OperatorClass(L)\n",
    "\n",
    "OPS_LIST.add_operators('ZZ')\n",
    "\n",
    "NUM_COEFFICIENTS = len(OPS_LIST)\n",
    "\n",
    "#Initialize parameters\n",
    "torch.manual_seed(CONFIG[\"seed_init\"])\n",
    "\n",
    "theta_init = torch.rand(NUM_COEFFICIENTS, dtype=torch.float32)\n",
    "# Initialize NN\n",
    "NN_INPUT_DIM = L\n",
    "\n",
    "params = {\"theta\": theta_init}\n",
    "\n",
    "# Add rotation parameters for each enabled field type\n",
    "if CONFIG['x_fields']:\n",
    "    params[\"rot_x\"] = torch.rand(L, dtype=torch.float32)\n",
    "if CONFIG['y_fields']:\n",
    "    params[\"rot_y\"] = torch.rand(L, dtype=torch.float32)\n",
    "if CONFIG['z_fields']:\n",
    "    params[\"rot_z\"] = torch.rand(L, dtype=torch.float32)\n",
    "\n",
    "# Update NN output dimension\n",
    "NN_OUTPUT_DIM = NUM_COEFFICIENTS + sum(CONFIG[f'{axis}_fields'] for axis in ['x', 'y', 'z']) * L\n",
    "\n",
    "model = MPS_MLP(NN_INPUT_DIM, CHI, NN_OUTPUT_DIM, num_dims = []) #num_dims is for optional intermediate layers\n",
    "n_epochs = CONFIG['N_epochs']\n",
    "\n",
    "t_grid_fine = torch.arange(0.0, CONFIG[\"t_max\"] + CONFIG[\"dt\"]/2, CONFIG[\"dt\"])\n",
    "learning_rate = CONFIG['learning_rate']\n",
    "\n",
    "train_model(model, params, n_epochs, single_qubit_probs, psi0, OPS_LIST, CONFIG, t_grid_fine, learning_rate, counts_shots)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903c0ef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637049d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retech_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
