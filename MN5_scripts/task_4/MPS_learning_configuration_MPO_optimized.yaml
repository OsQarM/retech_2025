# UPDATED CONFIGURATION FOR MPO TRAINING
# This configuration includes fixes and optimal settings for MPO convergence

# SYSTEM PARAMETERS
L: 4
bond_dimension_data: 4
bond_dimension_learning: 2
t_max: 1.0
initial_state_kind: "all_plus" # "all_zeros" or "all_plus"
data_kind: 'mps' # options, mps, zeros, plus, ghz

# HAMILTONIAN MODEL
hamiltonian_type: "custom"
x_fields: False #add local fields as rotations (not working yet)
y_fields: False
z_fields: False

# TRAINING PARAMETERS - IMPROVED FOR MPO
dt: 0.01
N_epochs: 500 
learning_rate: 0.01 
print_every: 50

# ============================================================================
# MPO ARCHITECTURE - CRITICAL SETTINGS
# ============================================================================

NN_TYPE: "mps"  # "mps" or "mpo"

# Option 2: Manual MPO size (only used if AUTO_MPO_SIZE = False)
MPO_SIZE: 64  #in mpo mode, it must be the cube of an integer (64, 126, 216, ...)

# MPO bond dimension
MAX_MPO_CHI: 4

# Use simple MPO architecture for debugging
SIMPLE_MPO: False  # Set to True if having convergence issues

TRAINABLE_MPO: False #train the mpo parameters

# MPO mode toggle
MPO_ON: True  # Actually use MPO decomposition

# ============================================================================
# REGULARIZATION AND STABILITY
# ============================================================================

lambda_reg: 0.01  # L2 regularization on parameters
noise_reg: 0.001

# Gradient clipping (handled in training function)
GRAD_CLIP_NORM: 1.0

# Learning rate schedule
USE_LR_SCHEDULER: False
LR_PATIENCE: 2000
LR_FACTOR: 0.5

# Early stopping
USE_EARLY_STOPPING: False
EARLY_STOP_PATIENCE: 5000


# ============================================================================
# COMPARISON SETTINGS
# ============================================================================

# For comparing MPO vs MPS performance
RUN_COMPARISON: False  # Set to True to run both and compare

 
# ============================================================================
# NOTES ON MPO CONVERGENCE
# ============================================================================

# If MPO is not converging well, try:
# 
# 1. Increase MAX_MPO_CHI (e.g., 4, 8, 16)
#    - Higher bond dimension = more expressivity
# 
# 2. Use SIMPLE_MPO: True
#    - Simpler architecture may converge better
# 
# 3. Decrease learning_rate (e.g., 0.0005)
#    - More stable training
# 
# 4. Increase lambda_reg (e.g., 0.05)
#    - Prevent parameter explosion
# 
# 5. Use smaller MPO_SIZE
#    - Less compression, easier optimization
#    - Try: 27 instead of 125
# 
# 6. Set AUTO_MPO_SIZE: True
#    - Let the code find optimal size
# 
# 7. Compare with MPO_ON: False
#    - Check if issue is MPO-specific or general architecture
# 
# 8. Start with MPS to verify data/physics code
#    - Then switch to MPO
